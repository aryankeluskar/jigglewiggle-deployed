import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";

/**
 * POST /api/coach
 *
 * Accepts a PoseSummary JSON + conversation history and returns
 * a short coaching message generated by OpenAI.
 *
 * Request body:
 * {
 *   summary: PoseSummary,          // current pose snapshot
 *   history: { role, content }[]   // recent coach conversation (last ~6 turns)
 * }
 *
 * Response:
 * { message: string }
 */

const SYSTEM_PROMPT = `You're a hype dance coach calling out real-time cues to a dancer matching a YouTube choreography. You'll get a JSON pose snapshot — reply with ONE spoken coaching line (max 15 words). This will be read aloud via TTS so write it exactly as spoken words: contractions, exclamations, rhythm. No written-text phrasing, no quotes, no JSON.

REFERENCE DATA (when present):
The "reference" field compares the dancer to the video choreography frame-by-frame.
- matchScore: 0-100 how close they are to the reference pose
- limbScores: per-limb accuracy (rightArm, leftArm, rightLeg, leftLeg, torso)
- worstLimb: the limb furthest from the reference
- refPoseLabel: what the reference pose looks like (e.g. "T-pose", "Arms up", "Star jump")
When reference data exists, PRIORITIZE it over generic body-mechanics feedback. Call out the specific limb and the target pose.

PHASE AWARENESS (use sessionSeconds):
- 0-15s: warm-up — encouraging, get-moving energy ("Let's go!", "Feel the beat!")
- 15-60s: corrections — specific, actionable cues about limbs and poses
- 60s+: refinement & hype — polish details, celebrate good runs

SCORE & TREND:
- score >= 80, steady/improving: hype it ("Yo, that was clean!", "Nailing it!")
- score < 40: urgent corrections on the worst limb
- trend "improving" after "declining": celebrate the comeback ("There it is! Back on it!")
- trend "declining": re-engage ("Where's that left arm? Get it up!")

BODY MECHANICS (fallback when no reference):
- motionEnergy < 0.01: they're frozen — get them moving
- motionEnergy > 0.1: too wild — tell them to control it
- armSymmetry > 0.15: cue mirroring
- armHeight > 0.1: hands too low
- torsoLean > 0.05: center their weight

STYLE:
- Vary structure: questions ("Where's that left arm?"), commands ("Hit it!"), reactions ("Yo, that was clean!")
- Sound like a real person coaching in the room, not a text prompt
- Never repeat the exact same line back-to-back
- Reply with ONLY the coaching line`;

export async function POST(req: NextRequest) {
  try {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      // Fallback: return a rule-based message if no API key configured
      return NextResponse.json(
        { message: "Set OPENAI_API_KEY in .env.local to enable AI coach!" },
        { status: 200 }
      );
    }

    const { summary, history } = await req.json();

    if (!summary) {
      return NextResponse.json(
        { error: "Missing summary in request body" },
        { status: 400 }
      );
    }

    const openai = new OpenAI({ apiKey });

    // Build messages array
    const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
      { role: "system", content: SYSTEM_PROMPT },
    ];

    // Include recent conversation history (last 6 exchanges for context)
    if (Array.isArray(history)) {
      for (const msg of history.slice(-6)) {
        messages.push({
          role: msg.role as "user" | "assistant",
          content: msg.content,
        });
      }
    }

    // Current pose data as the new user message
    messages.push({
      role: "user",
      content: `Current pose snapshot:\n${JSON.stringify(summary, null, 2)}`,
    });

    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages,
      max_tokens: 60,
      temperature: 0.7,
    });

    const message =
      completion.choices[0]?.message?.content?.trim() ?? "Keep moving!";

    // Generate speech audio via OpenAI TTS
    let audio: string | undefined;
    try {
      const ttsRes = await openai.audio.speech.create({
        model: "tts-1-hd",
        voice: "shimmer",
        input: message,
        response_format: "mp3",
        speed: 1.15,
      });
      const buf = Buffer.from(await ttsRes.arrayBuffer());
      audio = buf.toString("base64");
    } catch (ttsErr) {
      console.error("TTS error (falling back to text only):", ttsErr);
    }

    return NextResponse.json({ message, audio });
  } catch (err) {
    console.error("Coach API error:", err);
    return NextResponse.json(
      { message: "Keep going! You've got this!" },
      { status: 200 }
    );
  }
}
